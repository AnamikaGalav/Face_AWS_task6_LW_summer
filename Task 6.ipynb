{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import smtplib, subprocess, os, boto3, cv2\n",
    "import pywhatkit as kt\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining some functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def face_extractor(img):\n",
    "    #Function detects faces and returns the cropped face\n",
    "    #If no face detected, it returns the input image\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)    \n",
    "    if faces is ():\n",
    "        return None\n",
    "    # Crop all faces found\n",
    "    for (x,y,w,h) in faces:\n",
    "        cropped_face = img[y:y+h, x:x+w]\n",
    "    return cropped_face\n",
    "\n",
    "def face_detector(img):\n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "def send_mail(sender_email_id,sender_email_id_password,Mail_you_need_to_send,receiver_email_id):\n",
    "    s = smtplib.SMTP('smtp.gmail.com', 587)\n",
    "    s.starttls()#start TLS for security\n",
    "    s.login(sender_email_id, sender_email_id_password)#Authentication\n",
    "    mail = Mail_you_need_to_send#mail to be sent\n",
    "    s.sendmail(sender_email_id, receiver_email_id, mail)#sending the mail\n",
    "    s.quit()#terminating the session\n",
    "    print(\"Mail is sent\")\n",
    "    \n",
    "def send_whatsapp(p_num,whatsapp_msg):\n",
    "    print(\"Let's Automate Whatsapp!\")\n",
    "    #p_num ->the target phone number goes here!'\n",
    "    minute = pd.Timestamp.now().minute + 1\n",
    "    hour = pd.Timestamp.now().hour\n",
    "    kt.sendwhatmsg(p_num, whatsapp_msg, hour, minute)\n",
    "    \n",
    "def launch_ec2_create_and_attach_ebs():\n",
    "    #launching ec2 instance\n",
    "    os.system(\"aws ec2 run-instances --image-id ami-011c99152163a87ae --instance-type t2.micro --count 1 --subnet-id subnet-2eeeb462 --security-group-ids sg-251cdc59 --key-name \\\"Anamika Mitee\\\" \")\n",
    "    time.sleep(10)\n",
    "    \n",
    "    ec2 = boto3.resource('ec2')\n",
    "    for instance in ec2.instances.all():\n",
    "        InstanceId =   \"{0}\".format(instance.id)\n",
    "    InstanceId\n",
    "    #creating 5 GB volume\n",
    "    Volumeid = subprocess.getoutput('aws ec2 create-volume --availability-zone ap-south-1b --size 5 --query \\\"VolumeId\\\" --output text')\n",
    "    Volumeid\n",
    "    time.sleep(10)\n",
    "    \n",
    "    #attaching EBS volume to that instance\n",
    "    to_attach = f'aws ec2 attach-volume --device /dev/sdf --instance-id {InstanceId} --volume-id {Volumeid}'\n",
    "    to_attach\n",
    "    os.system(to_attach)\n",
    "    print(\"EC2 instance is launched, 5GB volume is created and attached to it!!!!! \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Names = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the id of user: 2\n",
      "Enter the name of user: CaptainAmerica\n",
      "['Anamika', 'CaptainAmerica']\n"
     ]
    }
   ],
   "source": [
    "ID = input(\"Enter the id of user: \")\n",
    "Name = input(\"Enter the name of user: \")\n",
    "\n",
    "Names.append(Name)\n",
    "print(Names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Face not found\n",
      "Collecting Samples Complete\n"
     ]
    }
   ],
   "source": [
    "#Load HAAR face classifier\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "#Initialize Webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "count = 0\n",
    "\n",
    "# Collect samples of your face from webcam input\n",
    "while True:\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    if face_extractor(frame) is not None:\n",
    "        count += 1\n",
    "        face = cv2.resize(face_extractor(frame), (200, 200))\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Save file in specified directory with unique name\n",
    "        file_name_path = \"./dataset/\" + Name + \".\" + ID +\".\"+ str(count) + \".jpg\"\n",
    "        cv2.imwrite(file_name_path, face)\n",
    "\n",
    "        # Put count on images and display live count\n",
    "        cv2.putText(face, str(count), (50, 50), cv2.FONT_HERSHEY_COMPLEX, 1, (0,255,0), 2)\n",
    "        cv2.imshow('Cropped img', face)\n",
    "        \n",
    "    else:\n",
    "        print(\"Face not found\")\n",
    "        pass\n",
    "\n",
    "    if cv2.waitKey(1) == 13 or count == 100: #13 is the Enter Key\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()      \n",
    "print(\"Collecting Samples Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained sucessefully\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "def Image_and_id(path):\n",
    "    image_paths = [os.path.join(path,f) for f in os.listdir(path)]\n",
    "    facesamples, Ids = [], []\n",
    "    \n",
    "    for imagepath in image_paths:\n",
    "        image = cv2.imread(imagepath, cv2.IMREAD_GRAYSCALE)\n",
    "        imagenp = np.asarray(image,dtype=np.uint8)\n",
    "        Id = int(os.path.split(imagepath)[-1].split(\".\")[1])\n",
    "        face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_classifier.detectMultiScale(imagenp, 1.3, 5)\n",
    "        for (x,y,w,h) in faces:\n",
    "            facesamples.append(imagenp[y:y+h, x:x+w])\n",
    "            Ids.append(Id)\n",
    "    return facesamples , Ids\n",
    "\n",
    "\n",
    "\n",
    "model  = cv2.face.LBPHFaceRecognizer_create()\n",
    "faces , Id = Image_and_id(\"./dataset/\")\n",
    "#Let's train our model \n",
    "model.train(faces, np.array(Id))\n",
    "print(\"Model trained sucessefully\")\n",
    "model.save(\"./Trained_model.yml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# running my facial recognization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "launched 81\n",
      "EC2 instance is launched, 5GB volume is created and attached to it!!!!! \n"
     ]
    }
   ],
   "source": [
    "#face recognition\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "face_classifier = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "\n",
    "def face_detector(img, size=0.5):\n",
    "    \n",
    "    # Convert image to grayscale\n",
    "    gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_classifier.detectMultiScale(gray, 1.3, 5)\n",
    "    if faces is ():\n",
    "        return img, []\n",
    "    \n",
    "    \n",
    "    for (x,y,w,h) in faces:\n",
    "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,255),2)\n",
    "        roi = img[y:y+h, x:x+w]\n",
    "        roi = cv2.resize(roi, (200, 200))\n",
    "    return img, roi\n",
    "\n",
    "launched = False\n",
    "sent = False\n",
    "\n",
    "# Open Webcam\n",
    "cap = cv2.VideoCapture(1)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    image, face = face_detector(frame)\n",
    "    try:\n",
    "        face = cv2.cvtColor(face, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        results = model.predict(face)\n",
    "        id = results[0]\n",
    "       \n",
    "        if results[1] < 500:\n",
    "            conf = int(100*(1- results[1]/400))\n",
    "            st = str(conf) + '% confidence of ' + Names[id-1]\n",
    "            cv2.putText(image, st, (100, 120), cv2.FONT_HERSHEY_COMPLEX, 1, (255,120,150), 2)\n",
    "            cv2.imshow('Face_Recognition', image ) \n",
    "            \n",
    "        if conf > 80 and id == 2 and launched == False:\n",
    "            cv2.imshow('Face_Recognition', image )  \n",
    "            print(\"launched\",conf)\n",
    "             #launching ec2 instance, creating 5GB volume and attaching to it\n",
    "            launch_ec2_create_and_attach_ebs()\n",
    "            launched = True\n",
    "            break\n",
    "            \n",
    "            \n",
    "        elif conf > 80 and id == 1 and sent == False:\n",
    "            cv2.imshow('Face_Recognition', image )  \n",
    "            #Send Mail\n",
    "            sender_email_id = \"aaviagalav024@gmail.com\"\n",
    "            sender_email_id_password = \"qtzlqwogugfuprps\"\n",
    "            Mail_you_need_to_send   = \"This is your face\"\n",
    "            receiver_email_id   = \"aaviagalav024@gmail.com\"\n",
    "            send_mail(sender_email_id,sender_email_id_password,Mail_you_need_to_send,receiver_email_id)\n",
    "            \n",
    "            #Send msg to a whatsapp number\n",
    "            p_num = \"+916264964403\"\n",
    "            whatsapp_msg = \"Hey Anamika! This is your face!!!\"\n",
    "            send_whatsapp(p_num,whatsapp_msg)\n",
    "            sent = True\n",
    "            break\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "\n",
    "            \n",
    "    except:\n",
    "        cv2.putText(image, \"No Face Found\", (50, 50) , cv2.FONT_HERSHEY_COMPLEX, 1, (0,0,255), 2)\n",
    "        cv2.imshow('Face_Recognition', image )\n",
    "        pass\n",
    "    \n",
    "    if cv2.waitKey(1) == 13: #13 is the Enter Key\n",
    "        break    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
